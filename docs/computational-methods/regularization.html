<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.34">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>regularization</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-c8ad9e5dbd60b7b70b38521ab19b7da4.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-57255bc51a02dad1602480f616b5f366.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent quarto-light">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="regularization-for-neural-networks" class="level1">
<h1>Regularization for Neural Networks</h1>
<div class="hidden">
<p><span class="math display">\[
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\R}{\mathbb{R}}
\DeclareMathOperator*{\argmin}{argmin}
\newcommand{\T}{^\mathsf{T}}
\]</span></p>
</div>
<p>As we’ve seen, deep neural networks can quickly become large and complicated, with far more parameters (weights, biases, feature maps, and so on) than any statistical model you’ve used before. This makes them vulnerable to overfitting their training data, and can result in models that generalize poorly to new data.</p>
<p>“Regularization” covers a broad category of methods to reduce this problem; <span class="citation" data-cites="DLB">@DLB</span> define regularization as “any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error” (section 5.2.2).</p>
<p>The simplest strategy might just be to make small networks. But real-world problems tend to involve complicated, high-dimensional relationships—or at least the kinds of real-world problems we try to solve with neural networks instead of linear models. It seems reasonable to expect that classifying high-resolution images or understanding written text should involve a highly complicated and nonlinear process, and a small network may be a poor approximation to that.</p>
<p>But a large network, while it reduces the bias (because it can get closer to the true relationship), has high variance. So we often start with large networks and apply regularization to reduce their variance.</p>
<section id="penalties" class="level2">
<h2 class="anchored" data-anchor-id="penalties">Penalties</h2>
<p>The most familiar form of regularization is penalization. For example, in least-squares regression, you have sometimes used estimators of the form <span class="math display">\[
\hat \beta = \argmin_\beta \underbrace{\|Y - X \beta\|_2^2}_\text{loss} +
\underbrace{\lambda \|\beta\|}_\text{penalty},
\]</span> where <span class="math inline">\(\|\beta\|\)</span> is some norm. When it’s the Euclidean (<span class="math inline">\(L_2\)</span>) norm, this is ridge regression; when it’s the Manhattan (<span class="math inline">\(L_1\)</span>) norm, this is the lasso. The penalty term “shrinks” the coefficients towards 0, meaning that the solution optimizing this objective has a smaller value of <span class="math inline">\(\|\beta\|\)</span> than one that simply minimized the squared-error loss.</p>
<p>You may also recall that it’s common to apply the penalization to the slopes but not to the intercept <span class="math inline">\(\beta_0\)</span>.</p>
<p>We can apply a similar sort of penalization to weights in neural networks. In <strong>?@sec-train-net</strong>, we defined the goal of gradient descent to be to minimize some loss function <span class="math inline">\(L\)</span>: <span class="math display">\[
\hat \theta = \argmin_\theta \frac{1}{n} \sum_{i=1}^n L(f(x_i; \theta), y_i).
\]</span> If we think of <span class="math inline">\(f\)</span> as the neural network, we could apply a penalty to <span class="math inline">\(\theta\)</span>, the neural network weights and biases: <span class="math display">\[
\hat \theta = \argmin_\theta \frac{1}{n} \sum_{i=1}^n L(f(x_i; \theta), y_i) +
\lambda \|\theta\|.
\]</span> If we choose the <span class="math inline">\(L_2\)</span> norm for the penalty, this is known as <em>weight decay</em>.</p>
<p>On fully connected layers, weight decay is typically applied to the weights and not the biases—for reasons related to the choice not to penalize intercepts in linear regression.</p>
<p>We call this “weight decay” because of the effect it has on the parameters. Consider performing gradient descent to minimize the objective function above. When the penalty term is the Euclidean norm, we can write the objective function as <span class="math display">\[
\tilde J(\theta) = J(\theta) + \lambda \theta\T\theta,
\]</span> where <span class="math inline">\(J(\theta)\)</span> is the sum of the losses. If we take the gradient with respect to the parameters <span class="math inline">\(\theta\)</span>, we obtain <span class="math display">\[
\nabla \tilde J(\theta) = \nabla J(\theta) + 2 \lambda \theta,
\]</span> and so an ordinary gradient step updates the parameters as <span class="math display">\[\begin{align*}
\theta &amp;\leftarrow \theta - \gamma (\nabla J(\theta) + 2 \lambda \theta) \\
&amp;\leftarrow \theta - \gamma \nabla J(\theta) - 2 \gamma \lambda \theta \\
&amp;\leftarrow (1 - 2\gamma \lambda)\theta - \gamma \nabla J(\theta).
\end{align*}\]</span> This looks like an ordinary gradient step, except that first, we shrink <span class="math inline">\(\theta\)</span> by a factor <span class="math inline">\((1 - 2 \gamma \lambda)\)</span>. In other words, the parameters decay toward the origin, leading to the term “weight decay.”</p>
<p>This also suggests an easy way to implement weight decay. Instead of adding the penalty to the loss function and tracking its gradient through backpropagation, our optimizer can simply shrink the weights toward zero on every gradient step.</p>
<p>This is how PyTorch implements gradient descent. Its optimizers include a <code>weight_decay</code> parameter that control the amount of decay (corresponding to <span class="math inline">\(\lambda\)</span> above), and they automatically apply the decay to <em>every</em> parameter in each network. Yes, that includes the biases, and feature maps in CNNs, and everything else, but it’s the easiest way to regularize in PyTorch.</p>
<p>(Tensorflow lets you separately apply weight decay to weights, biases, and other parameters, so you can decide which get regularized.)</p>
</section>
<section id="data-augmentation" class="level2">
<h2 class="anchored" data-anchor-id="data-augmentation">Data augmentation</h2>
<p>Another regularization approach is to make fake data.</p>
<p>Consider a classification task. You have, say, images that need to be labeled with a category. You know that very similar images should be put into the same category, where “similar” means something like “shifted slightly to the left” or “slightly darker” or “with a bit of random noise”. After all, a darker picture of a horse is still a picture of a horse.</p>
<p>If a classifier cannot generalize to slightly altered versions of its training data, presumably it won’t generalize well at all; at the least, generalizing well to slightly altered training data is better than not doing so.</p>
<p>Limiting the flexibility of the model is one way to ensure this, so that it is not so flexible that tiny changes to the inputs can dramatically change the outputs. But again, often we are using neural networks because we believe a large, complicated model is necessary.</p>
<p>An alternate approach is <em>data augmentation</em>. This involves augmenting your training data with additional “fake” data.</p>
<p>For example, in an image classification task, for every training image you might create new training images (with the same labels):</p>
<ul>
<li>one that’s moved a pixel to the left</li>
<li>one that’s moved a pixel to the right</li>
<li>one that’s moved a pixel upward</li>
<li>one that’s moved a pixel downward</li>
<li>one that’s slightly scaled down toward the center (as if it were zoomed out)</li>
<li>one that’s slightly scaled up from the center (as if it were zoomed in)</li>
<li>one where all the pixels are 10% brighter</li>
<li>one where all the pixels are 10% darker</li>
</ul>
<p>And so on and so on. The transformations must be chosen so that you can keep the same labels, so you shouldn’t choose transformations that change the classification of the image. But if you choose carefully, you can multiply the “size” of your training data by a large factor and produce a network that is more robust and generalizable.</p>
<p>For regression (rather than classification) tasks, it may be harder to use dataset augmentation. If you shift <span class="math inline">\(x\)</span>, how do you know what the new “true” <span class="math inline">\(y\)</span> should be?</p>
</section>
<section id="early-stopping" class="level2">
<h2 class="anchored" data-anchor-id="early-stopping">Early stopping</h2>
<p>We’ve repeatedly hinted that when training a neural network, we’re not actually trying to attain the global optimum of the loss function. That task is intractable—because there are many modes and gradient descent is not guaranteed to find the global optimizer—and in any case the global optimizer of the loss on the <em>training</em> data is likely to overfit.</p>
<p>In the homework, we’ve usually created training and test datasets, and tracked the test performance of the model after every epoch. We could use this as an estimate of generalization error and use it to decide when to stop our gradient descent process: if the test error does not improve for some number of iterations, we terminate the gradient descent and use the parameters from the iteration with the best test error.</p>
<p>This is called <em>early stopping</em> because it involves stopping gradient descent before we hit the specified maximum number of iterations (or epochs). It has the advantage that it requires very little additional computation, and in fact can save computation by letting you stop early.</p>
<p>Algorithm 7.1 of <span class="citation" data-cites="DLB">@DLB</span> suggests one specific way to do this. It involves specifying how often to check the test set and setting a parameter <span class="math inline">\(p\)</span>, the “patience”, or the number of times we’re willing to see the test set error get worse before terminating the optimization.</p>
<p>We can implement this in PyTorch by modifying our <code>train()</code> function to (a) store copies of the parameters every time we check the test error, (b) track the test errors to determine when to stop, and (c) return the parameters that attained the best test error, not the final parameters.</p>
<p>We can think of early stopping as being much like penalization. TODO draw diagram like DLB 7.4</p>
</section>
<section id="dropout" class="level2">
<h2 class="anchored" data-anchor-id="dropout">Dropout</h2>
<p>You may be familiar with <em>bagging</em> from other machine learning contexts. For example, random forests use bagging: multiple separate classification trees are built using different (bootstrapped) versions of the training data, and the random forest makes its predictions by having the individual trees vote on the correct classification. By averaging over many trees, each of which is very flexible, the overall variance of the estimator is reduced.</p>
<p>We could bag neural networks, but each neural network takes so long to train that this would be very expensive. The idea of averaging over separate models is appealing, though, so can we somehow approximate it?</p>
<p>Consider a large feed-forward network with fully connected layers. You could make many smaller networks by taking subsets of the nodes. These networks would not be completely independent—they would share the weights and biases for the nodes they have in common—but they’d still be different.</p>
<p>If there are <span class="math inline">\(n\)</span> nodes, there are <span class="math inline">\(2^n\)</span> subsets of nodes. Clearly we can’t fit all of those. But we <em>could</em> approximate somehow. The standard technique is <em>dropout</em>.</p>
<p>Suppose the neural network has <span class="math inline">\(m\)</span> hidden units across all its hidden layers. We choose a parameter <span class="math inline">\(p \in [0, 1]\)</span>. In each gradient descent step, we do the following:</p>
<ol type="1">
<li>Sample a vector <span class="math inline">\(\mu \in \{0, 1\}^m\)</span>, such that <span class="math inline">\(\mu_i \sim
\operatorname{Bernoulli}(1 - p)\)</span>.</li>
<li>Begin forward propagation. For each hidden layer node <span class="math inline">\(i\)</span>, multiply its output by <span class="math inline">\(\mu_i\)</span> before passing it to the next layer. This effectively zeroes the output of nodes where <span class="math inline">\(\mu_i = 0\)</span>. For nonzero outputs, multiply them by <span class="math inline">\(1/(1 - p)\)</span>.</li>
<li>Perform back-propagation and take a gradient step.</li>
<li>Return to step 1 for the next minibatch.</li>
</ol>
<p>Let’s go through each step.</p>
<p>First, think of <span class="math inline">\(\mu\)</span> as a mask. It determines which nodes are kept in the network (<span class="math inline">\(\mu_i = 1\)</span>) and which are dropped out (<span class="math inline">\(\mu_i = 0\)</span>). It means that on each minibatch, we only use a fraction <span class="math inline">\((1 - p)\)</span> of the nodes—like we are sampling a subset of nodes and using them for prediction.</p>
<p>Second, consider what we do once the network is trained and we use it for prediction. In bagging, we’d average over our many models; but we have only one network. Instead, we keep all the nodes in the network when making predictions—which is kind of like averaging over all the subsetted networks we use in training. That’s why we scaled the nodes during training: by scaling outputs by <span class="math inline">\(1/(1 - p)\)</span>, we ensured that when we don’t remove any nodes, the inputs to each node will still be roughly the same size on average.</p>
<p>I say “kind of like averaging” because it’s obviously not the same. In bagging, we’d train each model fully and then average them. Here, each “model” is just a different subset of the same network, and the subsetting is happening per iteration of training.</p>
<p>Dropout is a surprisingly powerful form of regularization, and works well in many contexts. It allows you to build a larger-than-necessary network and then essentially scale it down by choosing <span class="math inline">\(p\)</span>. It ensures the network is robust to perturbations, because during training the network must be robust to entire nodes being zeroed.</p>
<p>PyTorch implements this by making explicit dropout layers. If we specify a network as</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>nn.Sequential(</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">10</span>, <span class="dv">100</span>),</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    nn.Dropout(p<span class="op">=</span><span class="fl">0.5</span>),</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">100</span>, <span class="dv">1</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>we have told PyTorch to take the ReLU output (a vector of 100 numbers) and zero half of them. This is only done during training—the <code>Dropout</code> layer does nothing when the network is not in training mode. This is one reason why our <code>train()</code> and <code>test()</code> functions have been careful to set the network to be in training or evaluation mode; some layers, like dropout, change their behavior depending on the mode.</p>
</section>
<section id="batch-normalization" class="level2">
<h2 class="anchored" data-anchor-id="batch-normalization">Batch normalization</h2>
<p>TODO</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>