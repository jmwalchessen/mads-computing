<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.34">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>fitting-nets</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-c8ad9e5dbd60b7b70b38521ab19b7da4.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-57255bc51a02dad1602480f616b5f366.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent quarto-light">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="fitting-neural-networks-in-practice" class="level1">
<h1>Fitting Neural Networks in Practice</h1>
<div class="hidden">
<p><span class="math display">\[
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\R}{\mathbb{R}}
\DeclareMathOperator{\softmax}{softmax}
\DeclareMathOperator*{\argmin}{argmin}
\newcommand{\T}{^\mathsf{T}}
\]</span></p>
</div>
<p>As we’ve discussed, training a neural network is optimization, but of a certain kind. Unlike most mathematical optimization problems where we seek the true minimizer of a function, in deep learning the loss function is a surrogate: we care about the loss on the training data, but we care <em>more</em> about the loss when we generalize to new data. And the optimal training loss may not yield the optimal generalization error.</p>
<p>At the same time, neural networks are complex, nonlinear, nonconvex functions with many parameters. Optimizing them poses all kinds of challenges for our simple gradient-based methods.</p>
<p>Let’s discuss strategies for achieving better optimization for neural networks, keeping generalization error in mind as the final goal.</p>
<section id="common-problems" class="level2">
<h2 class="anchored" data-anchor-id="common-problems">Common problems</h2>
<p>To understand optimization, it may be useful to introduce some math.</p>
<div id="def-hessian" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 (Hessian matrix)</strong></span> The Hessian matrix <span class="math inline">\(H\)</span> of a function <span class="math inline">\(f(x) : \R^n \to \R\)</span> is defined so that its <span class="math inline">\((i, j)\)</span>th entry evaluated at a point <span class="math inline">\(x \in \R^n\)</span> is <span class="math display">\[
H(f)(x)_{i,j} = \frac{\partial^2}{\partial x_i \partial x_j} f(x).
\]</span> When the second partial derivatives are continuous, the order of differentiation can be swapped and the Hessian matrix is symmetric.</p>
</div>
<p>You may be used to thinking of the Hessian in one dimension: for a function <span class="math inline">\(f(x) : \R \to \R\)</span>, the Hessian is simply the second derivative. You use the second derivative to evaluate the function’s curvature at specific points. Similarly, the Hessian tells the curvature of a multidimensional function.</p>
<p>In univariate functions, you could use the Taylor expansion around a particular point <span class="math inline">\(x^*\)</span> to approximate the function. A second-order Taylor expansion would be <span class="math display">\[
f(x) \approx f(x^*) + (x - x^*) f'(x^*) + \frac{(x - x^*)}{2} f''(x^*).
\]</span> For a multivariate function, the Taylor expansion uses the gradient and the Hessian: <span class="math display">\[
f(x) \approx f(x^*) + (x - x^*)\T \nabla f(x^*) + \frac{1}{2} (x - x^*)\T
H(f)(x^*) (x - x^*).
\]</span></p>
<p>This decomposition suggests that understanding the Hessian of a function will help us understand its shape. Because (for most functions) the Hessian is real and symmetric, it can be decomposed into real eigenvalues and eigenvectors. If all eigenvalues are positive, the function is convex at this point; if they are all negative, it is concave.</p>
<p>(TODO show why this is, or maybe have a homework exercise?)</p>
<p>We can relate the Hessian to the steps of gradient descent. Suppose that at a particular gradient descent step, we are at the point <span class="math inline">\(x^{(0)}\)</span>. We calculate the gradient and update the parameters to <span class="math inline">\(x^{(1)} = x^{(0)} - \gamma \nabla
f(x^{(0)})\)</span>. In the Taylor approximation, the function’s value at the new point would be <span class="math display">\[\begin{align*}
f(x^{(1)}) &amp;\approx f(x^{(0)}) + (x^{(1)} - x^{(0)})\T \nabla f(x^{(0)}) +
\frac{1}{2} (x^{(1)} - x^{(0)})\T H(f)(x^{(0)}) (x^{(1)} - x^{(0)})\\
&amp;\approx f(x^{(0)}) - \gamma \nabla f(x^{(0)})\T \nabla f(x^{(0)}) +
\frac{\gamma^2}{2} \nabla f(x^{(0)})\T H(f)(x^{(0)}) \nabla f(x^{(0)}).
\end{align*}\]</span></p>
<p>Let’s consider the implications of this for optimization. If <span class="math inline">\(f\)</span> is the loss function for a particular network with a particular training dataset, and <span class="math inline">\(x^{(0)}\)</span> is the vector of weights and biases, each gradient step will reduce the loss by an amount related to the gradient <em>and the Hessian</em>. If the Hessian term is smaller than the gradient term, the loss will decrease; but if the Hessian term is large, the gradient step may not decrease the loss at all.</p>
<section id="poor-conditioning" class="level3">
<h3 class="anchored" data-anchor-id="poor-conditioning">Poor conditioning</h3>
<p>That brings us to our first problem: poor conditioning of the Hessian matrix. By “poor conditioning” we mean it has a large ratio between its largest and smallest eigenvalues. If the Hessian is poorly conditioned at a point, it means that in one direction (the direction of the eigenvector corresponding to the largest eigenvalue), the gradient will change very quickly, while in another direction (corresponding to the smallest eigenvalue), the gradient will change very slowly. A smart optimizer would move in a direction where the gradient is consistent, so we consistently increase the loss; but gradient descent goes wherever looks best now, even if after a step or two the loss would be quite flat.</p>
<p>Complicated neural networks often have regions of poor conditioning. The visible symptom is that the loss <em>increases</em> between gradient descent steps, even if you set the learning rate <span class="math inline">\(\gamma\)</span> to be small; to get the loss to decrease, you have to set it to very small values and wait ever-longer times for gradient descent to finish.</p>
<p>One way to detect this it to plot the norm of the gradient vector after each step: calculate <span class="math inline">\(\|\nabla f(x^{(i)})\|_2^2\)</span> and track it along with the loss. If the gradient keeps increasing, but the loss does not decrease very fast, gradient descent is making large jumps that do not effectively reduce the loss. You may need to pick smaller learning rates.</p>
</section>
<section id="multiple-local-minima" class="level3">
<h3 class="anchored" data-anchor-id="multiple-local-minima">Multiple local minima</h3>
<p>Nontrivial neural networks almost always are not <em>identifiable</em>. An identifiable model <span class="math inline">\(f(x; \theta)\)</span> is one where if <span class="math inline">\(f(x; \theta_1) = f(x; \theta_2)\)</span> for all <span class="math inline">\(x\)</span>, then <span class="math inline">\(\theta_1 = \theta_2\)</span>: the shape of the function is uniquely determined by the parameters.</p>
<p>In a simple fully connected feed-forward network, the network is not identifiable because we can swap nodes within each hidden layer. By rearranging the weights and biases accordingly, the model will give identical output for any input.</p>
<p>Similarly, consider node <span class="math inline">\(i\)</span> in a fully connected layer <span class="math inline">\(k\)</span> using ReLU as its activation function. Its output vector is <span class="math display">\[
(w_i\T h^{(k-1)} + b_i)_+
\]</span> If we’re in the region where this is positive, we can multiply <span class="math inline">\(w_i\)</span> by any constant <span class="math inline">\(c\)</span> if we also multiple the weights in the previous layer by <span class="math inline">\(1/c\)</span> (which would cause <span class="math inline">\(h^{(k-1)}\)</span> to be a factor of <span class="math inline">\(c\)</span> smaller). There is hence a hyperbola of weight values that give identical output.</p>
<p>If gradient descent reaches such a local minimum, the gradient will go to zero (or nearly zero, since we might land just outside the minimum) and stay there. Of course, in these nonidentifiable regions, every point has the same training loss; as long as the region is a minimum, it does not matter where in the region we land.</p>
<p>Because neural networks have many parameters, there may be many other local minima not arising from nonidentifiability. Normally this is a problem for optimization because you can end up in a local minimum with much larger loss than the true global minimum. But it is not clear how bad this is in large neural networks: it seems possible that most local minima have low values of the loss function, and so any one of them will do well <span class="citation" data-cites="DLB">[@DLB, section 8.2.2]</span>.</p>
</section>
<section id="saddle-points-and-plateaus" class="level3">
<h3 class="anchored" data-anchor-id="saddle-points-and-plateaus">Saddle points and plateaus</h3>
<p>Functions can have points with no gradient that are not minima or maxima: saddle points. (In fact, for high-dimensional functions like neural networks, saddle points can be more common than minima and maxima.)</p>
<p>In principle, gradient descent could get stuck at a saddle point, and this could be detected by checking the Hessian matrix: if it has both positive and negative eigenvalues, this is a saddle point. In practice, it’s unlikely for a gradient descent step to land on a point where the gradient is <em>exactly</em> zero, so it is unclear how big of a problem this actually is.</p>
<p>More concerning are large regions where the loss function is flat. These “plateaus” may not be minima, and both the gradient and Hessian would be zero, preventing gradient descent from making progress. Again, tracking the norms of the gradient and Hessian during optimization may be useful to detect this.</p>
</section>
<section id="sec-exploding-vanishing" class="level3">
<h3 class="anchored" data-anchor-id="sec-exploding-vanishing">Exploding and vanishing gradients</h3>
<p>Loss functions may have very steep “cliffs”. (For example, in a network where the output involves the multiplication of many weights, the gradient with respect to those weights may be very steep, because the multiplication of many terms can change dramatically as those terms change.) If gradient descent lands in such a region, it can make a dramatic jump.</p>
<p>This problem can again be detected by tracking the norm of the gradient at each step: if it jumps to a huge value on one step, there may be a cliff.</p>
<p>One simple approach to avoid this is <em>gradient clipping</em>, which simply does not allow the gradients to be larger than a preset maximum value. In PyTorch, the <code>torch.nn.utils.clip_grad_norm_</code> function goes through all parameters in a network, calculates the norm of the gradient, and rescales the gradient so the norm is no larger than a set value:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> data, labels <span class="kw">in</span> train_loader:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># reset gradients</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get predictions and loss</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> network(data)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> F.nll_loss(output, labels)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># calculate gradients</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># rescale all the gradients to have maximum norm 0.5</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    torch.nn.utils.clip_grad_norm_(network.parameters(), <span class="fl">0.5</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># perform the gradient descent step with the clipped gradients</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>A different kind of explosion can occur when networks become very deep. (This will particularly be a problem in recurrent networks, which we will see later.)</p>
<p>Consider, for example, a deep feed-forward network using ReLU. At each layer, the activations from the previous layer are multiplied by a weight matrix, so after many layers the output has been multiplied by many times. The gradient of such a long product is itself a product of those weight matrices—and so if they have large eigenvalues, the gradient may get huge; if they have small eigenvalues, it may get very close to 0. This causes either exploding gradients or vanishing gradients.</p>
<p>Feed-forward networks use different weight matrices for every layer, so it’s unlikely they will all have large or small eigenvalues and cause an explosion. But recurrent networks use the same weight matrix many times, and so can be vulnerable.</p>
</section>
<section id="dead-units" class="level3">
<h3 class="anchored" data-anchor-id="dead-units">Dead units</h3>
<p>TODO ReLU dead units</p>
</section>
</section>
<section id="practical-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="practical-algorithms">Practical algorithms</h2>
<p>Given all these potential problems, what optimization methods work well in practice?</p>
<section id="stochastic-gradient-descent" class="level3">
<h3 class="anchored" data-anchor-id="stochastic-gradient-descent">Stochastic gradient descent</h3>
<p>The most common optimizer is stochastic gradient descent, as introduced in <strong>?@sec-batch-sgd</strong>, with a reasonable minibatch size. But usually we do not use a fixed learning rate <span class="math inline">\(\gamma\)</span>. Instead, we choose a sequence <span class="math inline">\(\gamma_k\)</span> of learning rates such that <span class="math inline">\(\gamma_k \to 0\)</span>.</p>
<p>Ordinary gradient descent would not need this, because when we reach the minimum, the gradient would be zero and the optimizer would stop. But in SGD, we are estimating the gradient from a sample, so the gradient may not be exactly zero, and we’d continue going. According to <span class="citation" data-cites="DLB">@DLB</span> (section 8.3.1), a sufficient condition for convergence is to choose the learning rates so that <span class="math display">\[\begin{align*}
\sum_{k=1}^\infty \gamma_k &amp;= \infty \\
\sum_{k=1}^\infty \gamma_k^2 &amp;&lt; \infty.
\end{align*}\]</span> <span class="citation" data-cites="DLB">@DLB</span> reports that</p>
<blockquote class="blockquote">
<p>The learning rate may be chosen by trial and error, but it is usually best to choose it by monitoring learning curves that plot the objective function as a function of time. This is more of an art than a science, and most guidance on this subject should be regarded with some skepticism.</p>
</blockquote>
<p>As we will see in <a href="#sec-adaptive-learning-rate" class="quarto-xref">Section&nbsp;1.2.3</a>, it’s also common to use <em>adaptive</em> strategies that update the learning rate automatically, to avoid needing so much hand-tuning.</p>
</section>
<section id="momentum" class="level3">
<h3 class="anchored" data-anchor-id="momentum">Momentum</h3>
<p>Another strategy to improve stochastic gradient descent is to add <em>momentum</em>. The analogy is to think of gradient descent like a small ball rolling downhill on the surface of the loss function; a very light ball will always roll directly downhill, but a heavy one can pick up speed and continue moving in a direction even as the loss changes slope, because its momentum keeps it moving.</p>
<p>Using momentum requires an additional tuning parameter <span class="math inline">\(\alpha \in [0, 1)\)</span>. We also need a velocity vector <span class="math inline">\(v\)</span>, which we can think of as the current velocity of the ball.</p>
<p>On each gradient descent step, we calculate the gradient estimate over the minibatch. Call the resulting gradient vector <span class="math inline">\(g\)</span>.</p>
<p>We now update the parameters <span class="math inline">\(\theta\)</span> using the rule <span class="math display">\[\begin{align*}
v &amp;\leftarrow \alpha v - \gamma g\\
\theta &amp;\leftarrow \theta + v.
\end{align*}\]</span> At each step, we move by one unit in the direction of the velocity; the velocity depends on the gradient <em>but also the previous velocity</em>.</p>
<p>If you expand this out to write <span class="math inline">\(v\)</span> in terms of the gradient of the past several steps, you will see it is essentially an exponentially weighted moving average of the previous gradients. When <span class="math inline">\(\alpha \approx 0\)</span>, the previous gradients get only slight weight; when <span class="math inline">\(\alpha \approx 1\)</span>, the previous gradients get high weight.</p>
<p>As another analogy, you can think of this as smoothing the gradient vectors over time. With the right amount of smoothing, we can reduce problems like sudden gradient cliffs; and if stochastic gradient descent would want to bounce back and forth around a minimum, using the average gradient would result in the bounces averaging out and SGD taking much smaller steps.</p>
<p>In PyTorch, we can tell SGD to use momentum by using the <code>momentum</code> parameter to set <span class="math inline">\(\alpha\)</span>:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(network.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.25</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>There are other varieties of momentum that can be used, such as Nesterov momentum, but we won’t get into them here.</p>
</section>
<section id="sec-adaptive-learning-rate" class="level3">
<h3 class="anchored" data-anchor-id="sec-adaptive-learning-rate">Adaptive learning rates</h3>
<p>Because the learning rate is so important but can also be so difficult to tune, there are variety of methods for adjusting it automatically.</p>
<p>The basic idea is simple. If the gradient is small, don’t change the learning rate much; if the gradient is large, shrink it. But the details are complex. We’d like to apply this rule to each parameter separately—since some may have large gradients and some may have small—and we’d like to do so in an intelligent way that accounts for the randomness in stochastic gradient descent, so we aren’t making rapid wild changes to the learning rate.</p>
<p>RMSProp is one such algorithm (introduced by Geoffrey Hinton in a Coursera course, oddly enough). We start with a learning rate <span class="math inline">\(\gamma\)</span>, a decay rate <span class="math inline">\(\rho\)</span>, and a value <span class="math inline">\(\delta = 10^{-6}\)</span>. We initialize a vector <span class="math inline">\(r = 0\)</span> with one entry per parameter.</p>
<p>On each gradient descent step, we:</p>
<ol type="1">
<li>Calculate the gradient <span class="math inline">\(g\)</span> with respect to the minibatch.</li>
<li>Update <span class="math inline">\(r \leftarrow \rho r + (1 - \rho) g^2\)</span>, where <span class="math inline">\(g^2\)</span> is calculated elementwise in the gradient vector. Hence <span class="math inline">\(r\)</span> will be an exponentially weighted moving average of the squared gradients.</li>
<li>Update the parameters as <span class="math inline">\(\theta \leftarrow \theta -
\frac{\gamma}{\sqrt{\delta + r}} g\)</span>, where again the division and multiplication in the second term is done elementwise.</li>
</ol>
<p>The effective learning rate for a particular parameter <span class="math inline">\(\theta_i\)</span> is hence <span class="math display">\[
\frac{\gamma}{\sqrt{\delta + r_i}}.
\]</span> If the parameter’s gradients were large (positive or negative) in recent steps, its learning rate will be smaller; if they were small, the learning rate will be larger. You can see that <span class="math inline">\(\delta\)</span> is necessary to avoid dividing by zero in rare cases.</p>
<p>An improved version of RMSprop is Adam <span class="citation" data-cites="Kingma:2015">[@Kingma:2015]</span>. Adam is like RMSProp with momentum, and so the learning rate adaptation is applied to the velocity vector. (For details, see also <span class="citation" data-cites="DLB">@DLB</span>, algorithm 8.7.) Momentum helps keep gradient descent from getting stuck or from being too affected by cliffs, while the adaptation helps it converge when it gets near a minimum. The result is that Adam is one of the most popular current methods for training neural networks. It works well without usually requiring much manual tuning of hyperparameters.</p>
<p>Adam is supported by PyTorch. When initializing the optimizer, instead of using <code>SGD()</code> you can use <code>Adam</code>:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(network.parameters())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>It uses default values for the learning rate and momentum parameters, and these can be tweaked as needed.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>